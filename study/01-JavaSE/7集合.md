## 三、源码分析

### 3、hashmap

#### （2）成员变量的分析

```java
// 默认容量
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

// 最大容量
static final int MAXIMUM_CAPACITY = 1 << 30;

// 默认的加载因子
static final float DEFAULT_LOAD_FACTOR = 0.75f;

// 默认的一个树化的一个阈值 （THRESHOLD 阈值）
static final int TREEIFY_THRESHOLD = 8;

// 非树化的一个阈值
static final int UNTREEIFY_THRESHOLD = 6;

// 树化的最小容量，能看到一些信息，树化除了链表长度，对容量也有要求
static final int MIN_TREEIFY_CAPACITY = 64;

// 存储数据的hash表，就是一个数组
transient Node<K,V>[] table;

// 真实的负载因子
final float loadFactor;
```

#### （3）构造

```java
// 只是将默认的负载因子传递给了loadFactor
public HashMap() {
    this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
}

// 有传入的初始化容量
public HashMap(int initialCapacity) {
    this(initialCapacity, DEFAULT_LOAD_FACTOR);
}

// 有传入的初始化容量和负载因子
public HashMap(int initialCapacity, float loadFactor) {
    if (initialCapacity < 0)
        throw new IllegalArgumentException("Illegal initial capacity: " +
                                           initialCapacity);
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    if (loadFactor <= 0 || Float.isNaN(loadFactor))
        throw new IllegalArgumentException("Illegal load factor: " +
                                           loadFactor);
    // 计算新的负载因子和容量
    this.loadFactor = loadFactor;
    this.threshold = tableSizeFor(initialCapacity);
}  



/**
  * 返回一个值，大于等于传入的数字的一个2的次幂的数字，你传入15返回16，传入7返回8、
  * 保证了容量是2的次幂。为了后来计算hash槽做准备
  */
static final int tableSizeFor(int cap) {
    int n = cap - 1;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}


static final int tableSizeFor(int cap) {
    // 00010000 11101001 10001001 10000101  -- > 00010000 11101001 10001001 10000100  283,740,549
    // 看完了
    int n = cap - 1;
    // 00010000 11101001 10001001 10000101     n
    // 00001000 01110100 11000100 11000010     右移1位，保障2位是1
    // 00011000 11101101 11001101 11000111     n
    n |= n >>> 1;
    // 00011000 11101101 11001101 11000111     n
    // 00000110 00111011 01110011 01110001     右移2位，保障4位是1
    // 00011110 11111111 11111111 11110111     n
    n |= n >>> 2;
    // 00011110 11111111 11111111 11110111     n
    // 00000001 11101111 11111111 11111111     右移4位，保障8位是1
    // 00011111 11111111 11111111 11111111     n
    n |= n >>> 4;
    // 00011111 11111111 11111111 11111111     n
    // 00000000 00011111 11111111 11111111     右移8位，保障16位是1
    // 00011111 11111111 11111111 11111111     n
    n |= n >>> 8;
    // 00011111 11111111 11111111 11111111     n
    // 00000000 00000000 00011111 11111111     右移8位，保障32位是1
    // 00011111 11111111 11111111 11111111     n
    n |= n >>> 16;
    return  n + 1;
}
```

在构造的整个过程当中，并没有初始化hash表table。

#### （4）put方法

这个方法是核心，也是我们所需要研究的。很多的问题都是在这个方法当中。

```java
public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}

// 第一个关键点：key == null，说明我们的hashmap支持key为null
// 第二个关键点： (h = key.hashCode()) ^ (h >>> 16) ,这一点学完，学完putVal方法再看
// h          1010 0010 0001 1001 0010 1100 1010 1001
// h >>> 16   0000 0000 0000 0000 1010 0010 0001 1001 ( 0010 1100 1010 1001)
// 异或运算     1010 0010 0001 1001 1000 1110 1011 0000 
// 目的： 让高16位和低16位同时参与计算，将来计算hash槽时更加均匀
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
 final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
     // tab很明显就是hash表
     Node<K,V>[] tab; 
     // 就是个引用（指针），
     Node<K,V> p; 
     // 先不要管,n代表hash表的长度（tab）
     int n, i;
     // (tab = table) == null 将hash表赋值给tab，并且判断是不是null
     // 或者长度等于0，我就要扩容，构造没有初始化
     if ((tab = table) == null || (n = tab.length) == 0){
         // 那就扩容，还兼任初始化的责任（16）
         n = (tab = resize()).length;
     }
     // p == null,只不过有个给p赋值的过程
     // p = tab[i = (n - 1) & hash]
     // 其实 i是计算的槽位，你的数据往哪个格子里放
     // (n - 1) & hash 这是真实的计算过程，n确定是一个2的n次幂(100..)，hash是一个int值
     // (n-1)      0000 0000 0000 0000 0000 0000 0000 1111
     // (hash)     0010 0010 0010 0010 0000 0110 0000 1011
     // (result)   0000 0000 0000 0000 0000 0000 0000 1011       
     // 与运算之后的结果就是0~15，正好计算了一个槽位
     // 第一个思考的问题：为什么容量必须是2的次幂？ 0...01...1
     // 第二个思考的问题：为什么使用位移运算而不适用余运算？效率
     // 找到槽位，并且槽位没有数据，就直接newnode放进去
     if ((p = tab[i = (n - 1) & hash]) == null){
         // 创建了一个node
         tab[i] = newNode(hash, key, value, null);
     } else {
         // 只要进入else，说明这个槽位有数据了，就要搞链表了
         // 
         Node<K,V> e;
         // 键，泛型，当前插入数据的键
         K k;
         // 根据p = tab[i = (n - 1) & hash]，知道p是放在槽位上的node
         // p.hash == hash 说明发生了hash碰撞
         // (k = p.key) == key || (key != null && key.equals(k)) 判断的是key重复了
         if (p.hash == hash &&
             ((k = p.key) == key || (key != null && key.equals(k)))){
             // 覆盖
             e = p;
             
         // 判断是不是树形节点
         } else if (p instanceof TreeNode){
             e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
             
         // 否则就是链表的方式
         } else {
             for (int binCount = 0; ; ++binCount) {
                 if ((e = p.next) == null) {
                     // 这不就是链表吗？很明显这是尾插
                     p.next = newNode(hash, key, value, null);
                     if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                         // 树化
                         treeifyBin(tab, hash);
                     break;
                 }
                 // 判断链表中有没有key一样的，覆盖
                 if (e.hash == hash &&
                     ((k = e.key) == key || (key != null && key.equals(k))))
                     break;
                 p = e;
             }
         }
         if (e != null) { // existing mapping for key
             V oldValue = e.value;
             if (!onlyIfAbsent || oldValue == null)
                 e.value = value;
             afterNodeAccess(e);
             return oldValue;
         }
     }
     ++modCount;
     if (++size > threshold)
         resize();
     afterNodeInsertion(evict);
     return null;
 }
```

#### （5）扩容的方法

```java
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    // 旧的容量
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    // 旧的阈值
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap > 0) {
        // 容量大于最大值就取最大值
        if (oldCap >= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        
        // 这里体现了扩容的大小
        // newCap = oldCap << 1 相当于2倍
        } else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                 oldCap >= DEFAULT_INITIAL_CAPACITY)
            // 阈值月扩容二倍
            newThr = oldThr << 1; // double threshold
    // 旧的阈值大于零
    } else if (oldThr > 0){ // initial capacity was placed in threshold
        // 旧的阈值 = 新的容量
        newCap = oldThr;
       
    // 否则就是初始化，因为 == 0
    } else {               // zero initial threshold signifies using defaults
        // 否则新的容量就是默认的容量
        newCap = DEFAULT_INITIAL_CAPACITY;
        // 新的阈值就是 容量*负载因子
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    
    // 计算新的阈值，要么是相乘，要么Integer最大值
    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    
    // 将计算好的阈值赋值给 threshold
    threshold = newThr;
    @SuppressWarnings({"rawtypes","unchecked"})
    
    // 根据新的容量创建了新的hash表
    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    // 以下是重新拷贝的过程
    if (oldTab != null) {
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                if (e.next == null)
                    newTab[e.hash & (newCap - 1)] = e;
                else if (e instanceof TreeNode)
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else { // preserve order
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        next = e.next;
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
```

#### （6）树化的部分代码

```java
/**
  * Replaces all linked nodes in bin at index for given hash unless
  * table is too small, in which case resizes instead.
  */
final void treeifyBin(Node<K,V>[] tab, int hash) {
    int n, index; Node<K,V> e;
    if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
        // 优先扩容
        resize();
    else if ((e = tab[index = (n - 1) & hash]) != null) {
        TreeNode<K,V> hd = null, tl = null;
        do {
            TreeNode<K,V> p = replacementTreeNode(e, null);
            if (tl == null)
                hd = p;
            else {
                p.prev = tl;
                tl.next = p;
            }
            tl = p;
        } while ((e = e.next) != null);
        if ((tab[index] = hd) != null)
            hd.treeify(tab);
    }
}
```

为什么选择树化的长度是8，泊松分布

```text
 * 0:    0.60653066
 * 1:    0.30326533
 * 2:    0.07581633
 * 3:    0.01263606
 * 4:    0.00157952
 * 5:    0.00015795
 * 6:    0.00001316
 * 7:    0.00000094
 * 8:    0.00000006
 * more: less than 1 in ten million
```

普通节点

```java
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;
    final K key;
    V value;
    Node<K,V> next;

    Node(int hash, K key, V value, Node<K,V> next) {
        this.hash = hash;
        this.key = key;
        this.value = value;
        this.next = next;
    }
}
```

树形节点

```java
static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {
    TreeNode<K,V> parent;  // red-black tree links
    TreeNode<K,V> left;
    TreeNode<K,V> right;
    TreeNode<K,V> prev;    // needed to unlink next upon deletion
    boolean red;
}

static class Entry<K,V> extends HashMap.Node<K,V> {
    Entry<K,V> before, after;
    Entry(int hash, K key, V value, Node<K,V> next) {
        super(hash, key, value, next);
    }
}
```

**思考题：**

1、hashmap的key的hash怎么计算？

2、hashmap的hash表什么情况下会扩容？

3、hashmap中什么时候会树化？

4、为什么选择0.75为负载因子，8为树化阈值？



经常被问

* hashmap的key可以等于null

```java
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

key == null，它的hash=0

* 重写equals必须重写hashcode

因为hashmap在get的时候是先比较key的hash再比较equals，集合类是常用的，所以重写equals必须重写hashcode

* 什么时候会扩容

1. 初始化的时候
2. 集合的长度大于阈值
3. 树化之前

如果有链表要树化，树化之前会对数组长度进行判断，如果长度小于64，会优先扩容

* 什么时候树化

链表长度大于8，数组长度大于64

* 为什么选择树化的长度是8，泊松分布

```java
 * 0:    0.60653066
 * 1:    0.30326533
 * 2:    0.07581633
 * 3:    0.01263606
 * 4:    0.00157952
 * 5:    0.00015795
 * 6:    0.00001316
 * 7:    0.00000094
 * 8:    0.00000006
 * more: less than 1 in ten million
```

因为长度达到8的概率是极低的，百万分之一

### 4、hashset

hashset内部维护了一个hashmap
new hashset，就是new了一个hashmap
hashset.add，就是调用hashmap.put，添加的值作为hashmap的key，value就是一个空的Object
hashset.remove，就是调用hashmap.remove

## 四、集合的遍历

### 2、迭代器

```java
Map<String,String> user = new HashMap<>();
user.put("username","ydlclass");
user.put("password","ydl666888");
Set<Map.Entry<String, String>> entries = user.entrySet();
        
Iterator<Map.Entry<String, String>> iterator = entries.iterator();
while (iterator.hasNext()){
    Map.Entry<String, String> next = iterator.next();
    System.out.println(next.getKey());
    System.out.println(next.getValue());
}
```

### 3、增强for循环

```java
for (Map.Entry<String,String> entry : user.entrySet()){
    System.out.println(entry.getKey());
    System.out.println(entry.getValue());
}
```

增强for循环其实也是使用了迭代器

### 4、迭代中删除元素

第一种：回调指针

第二种：逆序遍历

#### 第三种：使用迭代器删除元素

```java
public static void main(String[] args){
    Iterator<String> iterator = names.iterator();
    while (iterator.hasNext()){
        // 记住next(),只能调用一次，因为每次调用都会选择下一个
        String name = iterator.next();
        if("lucy".equals(name)){
            iterator.remove();
        }
    }
    System.out.println(names);
}
```

## 五、其他的集合类

### 1、Linkedhashmap

Linkedhashmap在原来的基础上维护了一个双向链表，用来维护，插入的顺序。

![image-20210719162005725](..\img\image-20210719162005725-52d420fb.png)

```java
public LinkedHashMap() {
    super();
    accessOrder = false;
}
public LinkedHashMap(int initialCapacity,
                     float loadFactor,
                     boolean accessOrder) {
    super(initialCapacity, loadFactor);
    this.accessOrder = accessOrder;
}
```

如果accessOrder为true的话，则会把访问过的元素放在链表后面，放置顺序是访问的顺序 如果accessOrder为flase的话，则按插入顺序来遍历

在Linkedhashmap中有几个顺序，一个是插入顺序，一个是访问顺序。

我们还可以使用linkedhashmap实现LRU算法的缓存，所谓LRU:Least Recently Used,最近最少使用,即当缓存了,会优先淘汰那些最近不常访问的数据.即冷数据优先淘汰.

```java
public class LRU<K,V> extends LinkedHashMap<K,V> {
    private int max_capacity;
    public LRU(int initialCapacity,int max_capacity) {
        super(initialCapacity, 0.75F, true);
        this.max_capacity = max_capacity;
    }
    public LRU() {
        super(16, 0.75F, true);
        max_capacity = 8;
    }
    @Override
    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
        return size() > max_capacity;
    }
}
```

### 2、TreeMap

TreeMap底层实现是红黑树，所以天然支持排序。

```java
public TreeMap() {
    comparator = null;
}

public TreeMap(Comparator<? super K> comparator) {
    this.comparator = comparator;
} 



final int compare(Object k1, Object k2) {
    return comparator==null ? ((Comparable<? super K>)k1).compareTo((K)k2)
        : comparator.compare((K)k1, (K)k2);
}
    
    会吧key1强转为Comparable
```

我们尝试把一个没有实现Comparable的类传入TreeMap中，发现会抛出异常。

```java
Map<Dog,String> map = new TreeMap<>();

for (int i = 0; i < 100; i++) {
    map.put(new Dog(),"a");
}

        
Exception in thread "main" java.lang.ClassCastException: bb.Dog cannot be cast to java.lang.Comparable
    at java.util.TreeMap.compare(TreeMap.java:1294)
    at java.util.TreeMap.put(TreeMap.java:538)
    at bb.Animal.main(Animal.java:14)
```

已经很明显了，这就是我们之前学习的策略设计模式啊，我们可以自定义比较器，实现key的有序性。也可以让Dog类实现Comparable接口。

```java
public static void main(String[] args) {
    Map<Integer,String> map = new TreeMap<>(new Comparator<Integer>() {
        @Override
        public int compare(Integer o1, Integer o2) {
            return o1 - o2;
        }
    });

    for (int i = 0; i < 100; i++) {
        map.put(i,"a");
    }
    System.out.println(map);

}

{0=a, 1=a, 2=a, 3=a, 4=a, 5=a, 6=a, 7=a, 8=a, 9=a, 10=a, 11=a, 12=a, 13=a, 14=a, 15=a,
```

### 3、Collections

Collections是一个工具类，它给我们提供了一些常用的好用的操作集合的方法。

```java
ArrayList<Integer> list = new ArrayList<>();
list.add(12);
list.add(4);
list.add(3);
list.add(5);
//将集合按照默认的规则排序,按照数字从小到大的顺序排序
Collections.sort(list);
System.out.println("list = " + list);
System.out.println("===================");
//将集合中的元素反转
Collections.reverse(list);
System.out.println("list = " + list);
//addAll方法可以往集合中添加元素，也可往集合中添加一个集合
Collections.addAll(list,9,20,56);
//打乱集合中的元素
Collections.shuffle(list);
System.out.println("list = " + list);
 
//Arrays.asList方法可以返回一个长度内容固定的List集合
List<String> list2 = Arrays.asList("tom", "kobe", "jordan", "tracy","westbook","yaoming","ace","stephen");
//按照字符串首字符的升序排列
Collections.sort(list2);
```

**小问题：**

Arrays.asList(...)返回的是ArrayList吗？

返回的是Arrays的内部类，和java.util的ArrayList不一样

## 六、线程安全问题

ArrayList和HashMap线程不安全

### 1、并发修改异常

### 2、数据错误的问题

### 3、加锁解决

HashTable和Vector，这是两个很古老的类

 这两个类，其实很久没更新了，但是还是有面试会问，其实这两个类都有历史渊源，最开始就是在ArrayList和HashMap的基础上增加了Syncronized，但是后来ArrayList和hashMap一直在改进，这两个就成了历史了，反而现在问它们的区别其实意义不大了。

> HashMap和HashTable区别

1. HashMap的 key 和 value可以是null，而 Hashtable 传入null会抛空指针异常。
2. HashMap 把 Hashtable 的 contains 方法去掉了。因为 contains 方法容易让人引起误解。
3. 继承的类不一样，HashTable 继承自 Dictionary 类，而 HashMap 继承自AbstractMap
4. HashMap 是线程不安全的，HashTable 是线程安全的，HashTable 中的方法很多是用 Synchronized修饰的，所以HashTable 效率没有HashMap 高
5. Hashtable 和 HashMap 采用的 hash 算法不一样。HashMap 是用key值的hashcode高16位和低16位进行异或运算，如果key是 null hash就等于0。
6. 获取数组下标的算法不同。

> ArrayList和Vector的区别

1. ArrayList是线程不安全的，Vector是线程安全的。Vector类中的方法很多是用synchronized修饰的，所以Vector效率没有ArrayList高
2. 两个都是采用线性连续空间存储元素，但是当空间不足的时候，两个类的扩容方式是不同的。
3. Vector是一种老的动态数组，是线程同步的，效率很低，一般不赞成使用。

### 4、目前常用的线程安全集合

#### （1）CopyOnWriteList

CopyOnWriteList的核心就是写入的时候加锁，保证线程安全，读取的时候不加锁。不是一股脑，给所有的方法加锁。

#### （2）ConcurrentHashMap

1.8中的ConcurrentHashMap和HashMap的代码基本一样，只不过在有些操作上使用了cas，有些地方加了锁。

我们简单看看putVal算法

```java
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    // 计算hash
    int hash = spread(key.hashCode());
    int binCount = 0;
    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh;
        // 如果没有hash表，就创建一个
        if (tab == null || (n = tab.length) == 0)
            tab = initTable();
        // 给f赋值就是hash表中的元素
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            // 这里也是线程安全的
            // 如果没有就使用cas的方式添加
            if (casTabAt(tab, i, null,
                         new Node<K,V>(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        else if ((fh = f.hash) == MOVED)
            tab = helpTransfer(tab, f);
        else {
            V oldVal = null;
            // 看这是关键，这加了锁，f是什么啊？
            // f是头节点
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    if (fh >= 0) {
                        binCount = 1;
                        for (Node<K,V> e = f;; ++binCount) {
                            K ek;
                            if (e.hash == hash &&
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            Node<K,V> pred = e;
                            if ((e = e.next) == null) {
                                pred.next = new Node<K,V>(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    else if (f instanceof TreeBin) {
                        Node<K,V> p;
                        binCount = 2;
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                              value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }
            if (binCount != 0) {
                if (binCount >= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    addCount(1L, binCount);
    return null;
}
```

其实，面试很喜欢问1.7和1.8的区别

主要是1.7的分段锁是一个很经典的案例，造成这个的原因还有一个更重要的就是JDK1.7使用的是头插，而1.8改成尾插

JDK8以前是头插法，JDK8后是尾插法，那为什么要从头插法改成尾插法？

1. 因为头插法会造成循环链表
2. JDK7用头插是考虑到了一个所谓的热点数据的点(新插入的数据可能会更早用到)，但这其实是个伪命题,因为JDK7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置(就是因为头插)， 所以最后的结果 还是打乱了插入的顺序 ，所以总的来看支撑JDK7使用头插的这点原因也不足以支撑下去了 ，所以就干脆换成尾插 一举多得。

### 5、guava提供的不可变集合

```java
ImmutableList<String> list = ImmutableList.of("a","b");
ImmutableMultimap<String,Integer> map = ImmutableMultimap.of("a",2,"b",2,"c",3);
```

## 七、JUnit单元测试

### 2、JUnit 断言

1. `void assertEquals(boolean expected, boolean actual)`:检查两个变量或者等式是否平衡
2. `void assertTrue(boolean expected, boolean actual)`:检查条件为真
3. `void assertFalse(boolean condition)`:检查条件为假
4. `void assertNotNull(Object object)`:检查对象不为空
5. `void assertNull(Object object)`:检查对象为空
6. `void assertSame(boolean condition)`:assertSame() 方法检查两个相关对象是否指向同一个对象
7. `void assertNotSame(boolean condition)`:assertNotSame() 方法检查两个相关对象是否不指向同一个对象
8. `void assertArrayEquals(expectedArray, resultArray)`:assertArrayEquals() 方法检查两个数组是否相等

断言不成功会抛出异常，会有红色的进度条，断言能够帮助我们很好的预判结果，即使程序正常运行但是结果不正确，也会以失败结束。

### 3、JUnit 注解

1. `@Test`:这个注释说明依附在 JUnit 的 public void 方法可以作为一个测试案例。
2. `@Before`:有些测试在运行前需要创造几个相似的对象。在 public void 方法加该注释是因为该方法需要在 test 方法前运行。
3. `@After`:如果你将外部资源在 Before 方法中分配，那么你需要在测试运行后释放他们。在 public void 方法加该注释是因为该方法需要在 test 方法后运行。

### 4、命名规范

单元测试类的命名规范为：被测试类的类名+Test。.

单元测试类中测试方法的命名规范为：test+被测试方法的方法名+AAA，其中AAA为对同一个方法的不同的单元测试用例的自定义名称。

## 六、性能对比

### 1、Hashtable和ConcurrentHashMap

### 2、arraylist和linkedlist

#### 思考

- 尾插是数组快，而尾插的使用场景极多。
- 测试了各种迭代，遍历方法，ArrayList基本都是比LinkedList要快。
- 随机插入，链表会快很多
- 随机删除，链表的效率也是无比优于数组

## 七、Java8特性

### 1、接口默认方法

### 2、函数式接口

> 消费者，消费数据

```java
@FunctionalInterface
public interface Consumer<T> {
    void accept(T t);
}
```

> 供应商，给我们产生数据

```java
@FunctionalInterface
public interface Supplier<T> {
    T get();
}
```

> 断言，判断传入的t是不是满足条件

```java
@FunctionalInterface
public interface Predicate<T> {

    boolean test(T t);
}
```

> 函数，就是将一个数据转化成另一个数据

```java
@FunctionalInterface
public interface Function<T, R> {
    R apply(T t);
}
```

### 3、Optional

#### （1）简介

```
	 Optional类是Java8为了解决null值判断问题，借鉴google guava类库的Optional类而引入的一个同名Optional类，使用Optional类可以避免显式的null值判断（null的防御性检查），避免null导致的NPE（NullPointerException）。
```

#### （2）Optional对象的创建

```java
// 1、创建一个包装对象值为空的Optional对象
Optional<String> optStr = Optional.empty();
// 2、创建包装对象值非空的Optional对象
Optional<String> optStr1 = Optional.of("optional");
// 3、创建包装对象值允许为空的Optional对象
Optional<String> optStr2 = Optional.ofNullable(null);
```

#### （3）Optional 类典型接口的使用

```java
/**
    get()方法
    isPresent()方法
    ifPresent()方法
    orElse()方法
    orElseGet()方法
    orElseThrow()方法
*/
```

## 八、Stream编程

它提供串行(`.stream()`)和并行(`.parallelStream()`)两种模式进行汇聚操作，并发模式能够充分利用多核处理器的优势。通常，编写并行代码很难而且容易出错, 但使用Stream API无需编写一行多线程的代码，就可以很方便地写出高性能的并发程序。

Stream有几个特性：

1. Stream不存储数据，而是按照特定的规则对数据进行计算，一般会输出结果。
2. Stream不会改变数据源，通常情况下会产生一个新的集合或一个值。
3. Stream具有延迟执行特性，只有调用终端操作时，中间操作才会执行。

### 1、Stream流的创建

（1）通过  java.util.Collection.stream() 方法用集合创建流

```java
List<String> list = Arrays.asList("a", "b", "c");
// 创建一个顺序流
Stream<String> stream = list.stream();
// 创建一个并行流
Stream<String> parallelStream = list.parallelStream();
```

（2）使用java.util.Arrays.stream(T[] array)方法用数组创建流

```java
int[] array={1,3,5,6,8};
IntStream stream = Arrays.stream(array);
```

（3）使用Stream的静态方法：of()、iterate()、generate()

```java
Stream<Integer> stream = Stream.of(1, 2, 3, 4, 5, 6);
//0是初始值，每次+3，拿4个数据
Stream<Integer> stream2 = Stream.iterate(0, (x) -> x + 3).limit(4);
stream2.forEach(System.out::println);

Stream<Double> stream3 = Stream.generate(Math::random).limit(3);
stream3.forEach(System.out::println);
```

### 2、Stream的终止操作

#### （1）遍历/匹配（foreach/find/match）

```java
// 打印集合的元素
simpleList.stream().forEach(System.out::println);
// 其实可以简化操作的
simpleList.forEach(System.out::println);
```

```java
// 找到第一个
Optional<Integer> first = simpleList.stream().findFirst();
// 随便找一个,可以看到findAny()操作，返回的元素是不确定的，
// 对于同一个列表多次调用findAny()有可能会返回不同的值。
// 使用findAny()是为了更高效的性能。如果是数据较少，串行地情况下，一般会返回第一个结果，
// 如果是并行的情况，那就不能确保是第一个。
Optional<Integer> any = simpleList.parallelStream().findAny();
```

```java
// 判断有没有任意一个人年龄大于35岁
boolean flag = personList.stream().anyMatch(item -> item.getAge() > 35);
// 判断是不是所有人年龄都大于35岁
flag = personList.stream().allMatch(item -> item.getAge() > 35);
```

#### （2）归集(toList/toSet/toMap)

```java
List<Integer> collect = simpleList.stream().collect(Collectors.toList());
Set<Integer> collectSet = simpleList.stream().collect(Collectors.toSet());
Map<Integer,Integer> collectMap = simpleList.stream().collect(Collectors.toMap(item->item,item->item+1));

```

#### （3） 统计(count/averaging/sum/max/min）

```java
long count = new Random().ints().limit(50).count();
OptionalDouble average = new Random().ints().limit(50).average();
int sum = new Random().ints().limit(50).sum();
```

#### （4）归约(reduce)

把数字都归约到第一个参数n1上

> 案例：求`Integer`集合的元素之乘积。

```java
@Test
public void reduceTest(){
    //1是初始值，把数字都归约到第一个参数n1上
    Integer result = Stream.of(2, 1, 3, 4).reduce(1,(n1, n2) -> n1*n2);
    //24
    System.out.println(result);
}
```

#### (5）接合(joining)

```java
List<String> list = Arrays.asList("A", "B", "C");
String string = list.stream().collect(Collectors.joining("-"));
//A-B-C
```

#### （6）分组(partitioningBy/groupingBy)

```java
// 将员工按薪资是否高于5000分组
Map<Boolean, List<Person>> part = personList.stream().collect(Collectors.partitioningBy(x -> x.getSalary() > 5000));
    // 将员工按性别分组
Map<String, List<Person>> group = personList.stream().collect(Collectors.groupingBy(Person::getSex));
    // 将员工先按性别分组，再按地区分组
Map<String, Map<String, List<Person>>> group2 = personList.stream().collect(Collectors.groupingBy(Person::getSex, Collectors.groupingBy(Person::getArea)));
System.out.println("员工按薪资是否大于5000分组情况：" + part);
System.out.println("员工按性别分组情况：" + group);
System.out.println("员工按性别、地区：" + group2);
```

### 3、Stream中间操作

#### （1）筛选（filter）

```java
simpleList.stream().filter(item -> item > 17).forEach(System.out::println);
```

#### （2）映射(map/flatMap)

```java
personList.stream().map(item -> {
    item.setSalary(item.getSalary()+1000);
    return item;
}).forEach(System.out::println);
```

#### （3）排序(sorted)

```java
// 按工资升序排序（自然排序）
List<String> newList = personList.stream().sorted(Comparator.comparing(Person::getSalary)).map(Person::getName)
	.collect(Collectors.toList());
// 按工资倒序排序
List<String> newList2 = personList.stream().sorted(Comparator.comparing(Person::getSalary).reversed())
	.map(Person::getName).collect(Collectors.toList());
```

#### （4）peek操作

```java
// 在stream中间进行调试，因为stream不支持debug
List<Person> collect = personList.stream().filter(p -> p.getSalary() > 5000)
	.peek(System.out::println).collect(Collectors.toList());
// 修改元素的信息，给每个员工涨工资一千
personList.stream().peek(p -> p.setSalary(p.getSalary() + 1000))
    .forEach(System.out::println);
```

#### （5）其他操作

流也可以进行合并、去重、限制、跳过等操作。

```java
// distinct去掉重复数据   
// skip跳过几个数据
// limit限制使用几个数据
simpleList.stream().distinct().skip(2).limit(3).forEach(System.out::println);
```